[tool.poetry]
name = "llm-eval"
version = "0.1.0"
description = "Production-grade LLM evaluation framework with multi-metric analysis"
authors = ["Chinni Rakesh <rakeshchinni0000@gmail.com>"]
license = "MIT"
readme = "README.md"
packages = [{ include = "llm_eval", from = "src" }]

# -----------------------------
# Core dependencies
# -----------------------------
[tool.poetry.dependencies]
python = "^3.10"

# ---- SAFE ML STACK (NO META TENSORS) ----
torch = "2.1.2"
transformers = "4.39.3"
sentence-transformers = "2.5.1"

# Numerical / ML
numpy = "^1.26.0"
scikit-learn = "^1.3.0"
scipy = "^1.10.0"
pandas = "^2.2.0"

# CLI
typer = "^0.12.0"
rich = "^13.7.0"
click = "<8.3"

# Config & Validation
pydantic = "^2.6.0"
pyyaml = "^6.0.1"

# NLP & Metrics
nltk = "^3.8.1"
evaluate = "^0.4.1"

# LLM Providers
openai = "^1.14.0"
anthropic = "^0.25.0"

# Retry & Resilience
tenacity = "^8.2.3"

# Reporting / Visualization
jinja2 = "^3.1.3"
matplotlib = "^3.8.3"
seaborn = "^0.13.2"

# -----------------------------
# Dev / Testing
# -----------------------------
[tool.poetry.group.dev.dependencies]
pytest = "^8.1.1"
pytest-cov = "^4.1.0"
pytest-mock = "^3.12.0"

# -----------------------------
# CLI entrypoint
# -----------------------------
[tool.poetry.scripts]
llm-eval = "llm_eval.cli.main:app"

# -----------------------------
# Build system
# -----------------------------
[build-system]
requires = ["poetry-core>=1.8.0"]
build-backend = "poetry.core.masonry.api"
