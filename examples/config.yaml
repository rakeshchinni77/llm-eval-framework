dataset:
  path: benchmarks/rag_benchmark.jsonl

models:
  - name: model_a
    predictions: examples/model_outputs/model_a_outputs.jsonl

metrics:
  - name: bleu
  - name: rouge_l
  - name: bertscore

  - name: faithfulness
  - name: context_relevancy
  - name: answer_relevancy

  - name: llm_judge
    params:
      provider: openai
      model: gpt-4
      temperature: 0.0
